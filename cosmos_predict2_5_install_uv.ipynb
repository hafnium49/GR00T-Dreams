{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46ba23ac",
   "metadata": {},
   "source": [
    "\n",
    "# Cosmosâ€‘Predict **2.5** â€” Installation via **uv** (PythonÂ 3.10)\n",
    "\n",
    "This notebook automates the **official** installation steps from the Cosmosâ€‘PredictÂ 2.5 *Setup Guide* using the **uv** package manager. It creates an isolated `.venv` with **PythonÂ 3.10**, installs the package, and registers a Jupyter kernel so you can use it interactively.\n",
    "\n",
    "**System Requirements (from the guide):**\n",
    "- NVIDIA GPU with **Ampere** (RTXÂ 30 series, **A100**) or newer\n",
    "- NVIDIA **driver â‰¥ 570.124.06** (compatible with **CUDAÂ 12.8.1**)\n",
    "- **Linux x86â€‘64**, **glibc â‰¥ 2.31** (e.g., UbuntuÂ â‰¥Â 22.04)\n",
    "- **Python 3.10**\n",
    "\n",
    "> Checkpoints are fetched automatically during inference and postâ€‘training. To change where theyâ€™re cached, set the `HF_HOME` environment variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703dd0c1",
   "metadata": {},
   "source": [
    "## 1) Environment Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7366c149",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, re, sys, platform, subprocess, textwrap\n",
    "\n",
    "def run(cmd):\n",
    "    print(f\"$ {cmd}\")\n",
    "    p = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "    if p.stdout: print(p.stdout.strip())\n",
    "    if p.stderr and p.returncode != 0: print(p.stderr.strip())\n",
    "    return p\n",
    "\n",
    "print(\"ðŸ”Ž Host\")\n",
    "print(\"OS:\", platform.platform())\n",
    "print(\"Python:\", sys.version.split()[0])\n",
    "try:\n",
    "    print(\"glibc:\", platform.libc_ver())\n",
    "except Exception as e:\n",
    "    print(\"glibc: <unavailable>\", e)\n",
    "\n",
    "print(\"\\nðŸ”Ž NVIDIA Driver / CUDA\")\n",
    "out = run(\"nvidia-smi --query-gpu=name,driver_version,compute_cap --format=csv,noheader 2>/dev/null\")\n",
    "if out.returncode != 0:\n",
    "    # Fallback to generic nvidia-smi\n",
    "    out2 = run(\"nvidia-smi 2>/dev/null\")\n",
    "    text = (out.stdout or \"\") + \"\\n\" + (out2.stdout or out2.stderr or \"\")\n",
    "else:\n",
    "    text = out.stdout\n",
    "\n",
    "m_drv = re.search(r\"([0-9]+\\.[0-9]+\\.[0-9]+)\", text) or re.search(r\"Driver Version:\\s*([0-9.]+)\", text)\n",
    "driver = m_drv.group(1) if m_drv else \"unknown\"\n",
    "m_cuda = re.search(r\"CUDA Version:\\s*([0-9.]+)\", text)\n",
    "cuda = m_cuda.group(1) if m_cuda else \"unknown\"\n",
    "\n",
    "print(\"Driver:\", driver)\n",
    "print(\"CUDA:  \", cuda)\n",
    "\n",
    "def vtuple(v):\n",
    "    try: return tuple(map(int, v.split(\".\")))\n",
    "    except: return (0,0,0)\n",
    "\n",
    "meets_driver = vtuple(driver) >= (570,124,6)\n",
    "print(\"Meets driver â‰¥ 570.124.06:\", meets_driver)\n",
    "\n",
    "print(\"\\nâš ï¸  Note: Cosmosâ€‘PredictÂ 2.5 requires Ampere or newer (compute capability â‰¥ 8.0). \"\n",
    "      \"Some cloud notebooks may assign older GPUs.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79293374",
   "metadata": {},
   "source": [
    "## 2) Install **uv** (package manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c539249",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%bash\n",
    "set -euo pipefail\n",
    "echo \"Installing uvâ€¦\"\n",
    "curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "~/.local/bin/uv --version || true\n",
    "\n",
    "# Persist PATH for current shell sessions launched by bash in this notebook\n",
    "echo 'export PATH=\"$HOME/.local/bin:$PATH\"' >> ~/.bashrc\n",
    "export PATH=\"$HOME/.local/bin:$PATH\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b721f88a",
   "metadata": {},
   "source": [
    "## 3) Clone **cosmos-predict2.5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8207f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%bash\n",
    "set -euo pipefail\n",
    "REPO_URL=\"https://github.com/nvidia-cosmos/cosmos-predict2.5.git\"\n",
    "if [ -d \"cosmos-predict2.5\" ]; then\n",
    "  echo \"Repo already exists, pulling latestâ€¦\"\n",
    "  (cd cosmos-predict2.5 && git pull --ff-only)\n",
    "else\n",
    "  echo \"Cloning $REPO_URL\"\n",
    "  git clone \"$REPO_URL\"\n",
    "fi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99486ad",
   "metadata": {},
   "source": [
    "## 4) Create `.venv` (PythonÂ 3.10) with **uv** and install the package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e8b678",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%bash\n",
    "set -euo pipefail\n",
    "cd cosmos-predict2.5\n",
    "\n",
    "# Create/refresh the project virtual environment from pyproject/uv.lock\n",
    "uv --version\n",
    "echo \"Syncing dependencies into .venv (this installs Python 3.10 as needed)â€¦\"\n",
    "uv sync\n",
    "\n",
    "echo \"Registering Jupyter kernel: Python 3.10 (cosmos-predict2.5)\"\n",
    "uv run python -m ipykernel install --user --name cosmos-predict2_5 --display-name \"Python 3.10 (cosmos-predict2.5)\"\n",
    "\n",
    "echo \"Verifying Python inside .venv:\"\n",
    "uv run python -c \"import sys; print(sys.version); print(sys.executable)\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a098c29b",
   "metadata": {},
   "source": [
    "\n",
    "> **Alternative (conda/active env)**  \n",
    "> If you already activated a PythonÂ 3.10 environment (e.g., conda), you can install into the **active** env instead of creating `.venv`:\n",
    ">\n",
    "> ```bash\n",
    "> cd cosmos-predict2.5\n",
    "> uv sync --active --inexact\n",
    "> ```\n",
    "> This follows the official guideâ€™s alternative path.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229863f2",
   "metadata": {},
   "source": [
    "## 5) (Optional) Configure `HF_HOME` for checkpoint cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d120e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, pathlib, subprocess, textwrap\n",
    "\n",
    "# Choose a cache directory (edit as desired)\n",
    "cache_dir = \"/content/hf_cache\" if Path(\"/content\").exists() else str(Path.home() / \"hf_cache\")\n",
    "Path(cache_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Persist for future shells\n",
    "bashrc_line = f'export HF_HOME=\"{cache_dir}\"\\n'\n",
    "with open(Path.home()/\".bashrc\", \"a\") as f:\n",
    "    f.write(bashrc_line)\n",
    "\n",
    "os.environ[\"HF_HOME\"] = cache_dir\n",
    "print(\"HF_HOME set to:\", os.environ[\"HF_HOME\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a188722e",
   "metadata": {},
   "source": [
    "## 6) Smoke Test (import the package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f17481",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%bash\n",
    "set -euo pipefail\n",
    "cd cosmos-predict2.5\n",
    "echo \"Trying to import cosmos_predict2 from the .venvâ€¦\"\n",
    "uv run python - << 'PY'\n",
    "import sys\n",
    "print(\"Python:\", sys.version)\n",
    "try:\n",
    "    import cosmos_predict2\n",
    "    ver = getattr(cosmos_predict2, \"__version__\", \"unknown\")\n",
    "    print(\"âœ… cosmos_predict2 import OK | version:\", ver)\n",
    "except Exception as e:\n",
    "    print(\"âŒ Import failed:\", e)\n",
    "    raise SystemExit(1)\n",
    "PY\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0e07d7",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Notes & Troubleshooting\n",
    "\n",
    "- **Automatic checkpoints**: Models are downloaded on first use. To relocate the cache, set `HF_HOME` (see the cell above).\n",
    "- **Driver/CUDA errors**: If you see *â€œCUDA driver version insufficientâ€*, update your NVIDIA driver to a version compatible with **CUDAÂ 12.8.1**.\n",
    "  Check with:\n",
    "  ```bash\n",
    "  nvidia-smi | grep \"CUDA Version:\"\n",
    "  ```\n",
    "- **OOM**: Prefer **2B** models, reduce resolution/FPS/batch size, or use multiâ€‘GPU.\n",
    "- **Docker path** (advanced): If you have Docker + NVIDIA Container Toolkit installed, you can run the project containerized:\n",
    "  ```bash\n",
    "  docker run --gpus all --rm -v .:/workspace -v /workspace/.venv -it $(docker build -q .)\n",
    "  ```\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
