{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosmos Predict2 Full Pipeline on A100\\n\n",
    "\\n\n",
    "This notebook runs both T5 encoding and Cosmos Predict2 inference on a single A100 GPU.\\n\n",
    "\\n\n",
    "**Requirements:**\\n\n",
    "- Google Colab with A100 runtime\\n\n",
    "- 40GB GPU memory\\n\n",
    "\\n\n",
    "**Note:** Make sure to select `Runtime > Change runtime type > A100 GPU` before running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. Installation Setup\n\nChoose installation method: GitHub source (latest features) or PyPI (stable release)."
  },
  {
   "cell_type": "code",
   "source": "%%capture\n# Install other required dependencies\n!pip install -q transformers accelerate bitsandbytes\n!pip install -q decord einops imageio[ffmpeg]\n!pip install -q opencv-python-headless pillow\n\nprint(\"Installation complete!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Install Additional Dependencies",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "%%capture\nif not USE_GITHUB:\n    # Install PyTorch with CUDA support\n    !pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n    \n    # Install Cosmos Predict2 from PyPI\n    !pip install -q \"cosmos-predict2[cu126]\" --extra-index-url https://nvidia-cosmos.github.io/cosmos-dependencies/cu126_torch260/simple\n    \n    print(\"‚úÖ Installed from PyPI\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Install from PyPI",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "%%capture\nif USE_GITHUB:\n    # Clone the repository\n    !git clone https://github.com/NVIDIA/Cosmos-Predict2.git /content/cosmos-predict2\n    \n    # Change to the repo directory\n    import os\n    os.chdir('/content/cosmos-predict2')\n    \n    # Install PyTorch with CUDA support\n    !pip install -q --upgrade pip\n    !pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n    \n    # Install cosmos-predict2 from source with CUDA support\n    !pip install -q -e \".[cu126]\" --extra-index-url https://nvidia-cosmos.github.io/cosmos-dependencies/cu126_torch260/simple\n    \n    # Add to Python path\n    import sys\n    sys.path.insert(0, '/content/cosmos-predict2')\n    \n    print(\"‚úÖ Installed from GitHub source\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Install from GitHub Source",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "%%capture\n# Set installation method\nUSE_GITHUB = True  # Set to True for latest features from GitHub, False for stable PyPI release\n\nif USE_GITHUB:\n    print(\"Installing Cosmos Predict2 from GitHub source...\")\nelse:\n    print(\"Installing Cosmos Predict2 from PyPI...\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify installations and setup paths\n",
    "import pkg_resources\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add cosmos-predict2 to path if using GitHub installation\n",
    "if os.path.exists('/content/cosmos-predict2'):\n",
    "    sys.path.insert(0, '/content/cosmos-predict2')\n",
    "    COSMOS_PATH = '/content/cosmos-predict2'\n",
    "    print(f\"‚úÖ Using Cosmos Predict2 from GitHub: {COSMOS_PATH}\")\n",
    "else:\n",
    "    COSMOS_PATH = None\n",
    "    print(\"Using Cosmos Predict2 from pip installation\")\n",
    "\n",
    "# Verify key packages\n",
    "packages = ['cosmos-predict2', 'transformers', 'torch', 'decord']\n",
    "for package in packages:\n",
    "    try:\n",
    "        version = pkg_resources.get_distribution(package).version\n",
    "        print(f\"‚úÖ {package}: {version}\")\n",
    "    except:\n",
    "        # For GitHub install, cosmos-predict2 might not show up in pkg_resources\n",
    "        if package == 'cosmos-predict2' and COSMOS_PATH:\n",
    "            print(f\"‚úÖ cosmos-predict2: installed from source at {COSMOS_PATH}\")\n",
    "        else:\n",
    "            print(f\"‚ùå {package} not found\")\n",
    "\n",
    "# Test import\n",
    "try:\n",
    "    from cosmos_predict2.inference import Video2WorldPipeline\n",
    "    print(\"\\n‚úÖ Cosmos Predict2 imports working correctly\")\n",
    "except ImportError as e:\n",
    "    print(f\"\\n‚ùå Import error: {e}\")\n",
    "    print(\"Trying alternative import...\")\n",
    "    try:\n",
    "        # Add imaginaire to path as well\n",
    "        if COSMOS_PATH:\n",
    "            sys.path.insert(0, os.path.join(COSMOS_PATH, 'imaginaire'))\n",
    "        from imaginaire.constants import get_cosmos_predict2_video2world_checkpoint\n",
    "        print(\"‚úÖ Alternative import successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Mount Google Drive for automatic saving\n",
    "# RECOMMENDED: Set to True to prevent data loss\n",
    "mount_drive = True  # Set to True to auto-save outputs to Google Drive\n",
    "\n",
    "if mount_drive:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    print(\"‚úÖ Google Drive mounted at /content/drive\")\n",
    "    \n",
    "    # Create output directory in Drive\n",
    "    import os\n",
    "    from datetime import datetime\n",
    "    \n",
    "    # Create timestamped folder for this session\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    drive_output_dir = f\"/content/drive/MyDrive/cosmos_outputs_{timestamp}\"\n",
    "    os.makedirs(drive_output_dir, exist_ok=True)\n",
    "    print(f\"üìÅ Output directory created: {drive_output_dir}\")\n",
    "    print(\"‚ö†Ô∏è All outputs will be automatically saved to Google Drive\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è WARNING: Google Drive not mounted - outputs may be lost if runtime disconnects!\")\n",
    "    print(\"   Set mount_drive=True to enable automatic saving\")\n",
    "    drive_output_dir = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Model Checkpoints\n",
    "MODEL_SIZE = \"2B\"  # Options: \"2B\", \"5B\", \"14B\"\n",
    "\n",
    "print(f\"Downloading Cosmos Predict2-{MODEL_SIZE} checkpoint...\")\n",
    "print(\"This may take a few minutes...\")\n",
    "\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "# For GitHub installation, save checkpoints within the repo\n",
    "if COSMOS_PATH:\n",
    "    checkpoint_base_dir = os.path.join(COSMOS_PATH, \"checkpoints\")\n",
    "    os.makedirs(checkpoint_base_dir, exist_ok=True)\n",
    "else:\n",
    "    checkpoint_base_dir = \"/content/cosmos_checkpoints\"\n",
    "\n",
    "checkpoint_dir = snapshot_download(\n",
    "    repo_id=f\"nvidia/Cosmos-Predict2-{MODEL_SIZE}-Video2World\",\n",
    "    cache_dir=checkpoint_base_dir,\n",
    "    resume_download=True\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Checkpoint downloaded to: {checkpoint_dir}\")\n",
    "\n",
    "# Create symlinks for GitHub installation to match expected paths\n",
    "if COSMOS_PATH:\n",
    "    nvidia_dir = os.path.join(COSMOS_PATH, \"checkpoints\", \"nvidia\")\n",
    "    os.makedirs(nvidia_dir, exist_ok=True)\n",
    "    \n",
    "    link_path = os.path.join(nvidia_dir, f\"Cosmos-Predict2-{MODEL_SIZE}-Video2World\")\n",
    "    if not os.path.exists(link_path):\n",
    "        os.symlink(checkpoint_dir, link_path)\n",
    "        print(f\"‚úÖ Created symlink: {link_path}\")\n",
    "    \n",
    "    # Also check for tokenizer\n",
    "    tokenizer_path = os.path.join(checkpoint_dir, \"tokenizer\", \"tokenizer.pth\")\n",
    "    if not os.path.exists(tokenizer_path):\n",
    "        print(\"‚ö†Ô∏è Tokenizer not found in checkpoint, will download separately if needed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prompts for paper manipulation task (same as original notebook)\n",
    "prompts = [\n",
    "    \"A robotic arm picks up white paper and places it into a red square target area on the table.\",\n",
    "    \"High-definition video of SO-101 robot manipulating paper with precise movements.\",\n",
    "    \"Robot gripper grasps paper and moves it to designated red square zone.\",\n",
    "    \"Automated paper handling: robot transfers white sheet to red target area.\",\n",
    "]\n",
    "\n",
    "# Encode all prompts\n",
    "print(\"Encoding prompts...\")\n",
    "encoded_prompts = {}\n",
    "\n",
    "for prompt in prompts:\n",
    "    encoded = t5_encoder.encode(prompt)\n",
    "    encoded_prompts[prompt] = encoded[\"encoder_hidden_states\"]\n",
    "    print(f\"‚úÖ Encoded: '{prompt[:40]}...' Shape: {encoded['encoder_hidden_states'].shape}\")\n",
    "\n",
    "print(f\"\\nüíæ Current GPU memory: {torch.cuda.memory_allocated()/1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Mount Google Drive (Optional)\\n\n",
    "Mount your Google Drive if you have videos or want to save outputs there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cosmos_predict2.inference import (\n",
    "    Video2WorldPipeline,\n",
    "    get_cosmos_predict2_video2world_pipeline,\n",
    ")\n",
    "\n",
    "print(f\"Loading Cosmos Predict2-{MODEL_SIZE} pipeline...\")\n",
    "\n",
    "# Create pipeline configuration\n",
    "config = get_cosmos_predict2_video2world_pipeline(model_size=MODEL_SIZE)\n",
    "\n",
    "# Update config to use our downloaded checkpoint\n",
    "if COSMOS_PATH:\n",
    "    # GitHub installation - use local checkpoint paths\n",
    "    checkpoint_path = os.path.join(\n",
    "        COSMOS_PATH,\n",
    "        \"checkpoints\",\n",
    "        \"nvidia\",\n",
    "        f\"Cosmos-Predict2-{MODEL_SIZE}-Video2World\"\n",
    "    )\n",
    "    \n",
    "    # Check which model file exists\n",
    "    model_16fps = os.path.join(checkpoint_path, \"model-720p-16fps.pt\")\n",
    "    model_10fps = os.path.join(checkpoint_path, \"model-720p-10fps.pt\")\n",
    "    \n",
    "    if os.path.exists(model_16fps):\n",
    "        config['dit_checkpoint_path'] = model_16fps\n",
    "        print(f\"Using 16fps model: {model_16fps}\")\n",
    "    elif os.path.exists(model_10fps):\n",
    "        config['dit_checkpoint_path'] = model_10fps\n",
    "        print(f\"Using 10fps model: {model_10fps}\")\n",
    "    else:\n",
    "        # Fallback to checkpoint_dir from HuggingFace\n",
    "        config['dit_checkpoint_path'] = os.path.join(checkpoint_dir, \"model-720p-16fps.pt\")\n",
    "        print(f\"Using HF checkpoint: {config['dit_checkpoint_path']}\")\n",
    "else:\n",
    "    # PyPI installation - use downloaded checkpoint\n",
    "    config['dit_checkpoint_path'] = os.path.join(\n",
    "        checkpoint_dir,\n",
    "        \"model-720p-16fps.pt\"  # or \"model-720p-10fps.pt\" for 10fps\n",
    "    )\n",
    "\n",
    "# Initialize pipeline\n",
    "try:\n",
    "    cosmos_pipe = Video2WorldPipeline.from_config(config)\n",
    "    cosmos_pipe = cosmos_pipe.to(\"cuda\")\n",
    "    cosmos_pipe.eval()\n",
    "    \n",
    "    print(f\"‚úÖ Cosmos pipeline loaded successfully\")\n",
    "    print(f\"üíæ Current GPU memory: {torch.cuda.memory_allocated()/1024**3:.2f} GB\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading pipeline: {e}\")\n",
    "    print(\"\\nTrying alternative loading approach...\")\n",
    "    \n",
    "    # Alternative approach matching the original notebook\n",
    "    if COSMOS_PATH:\n",
    "        os.chdir(COSMOS_PATH)\n",
    "        \n",
    "    try:\n",
    "        from imaginaire.constants import get_cosmos_predict2_video2world_checkpoint\n",
    "        dit_path = get_cosmos_predict2_video2world_checkpoint(model_size=MODEL_SIZE)\n",
    "        \n",
    "        cosmos_pipe = Video2WorldPipeline.from_config(\n",
    "            config=get_cosmos_predict2_video2world_pipeline(model_size=MODEL_SIZE),\n",
    "            dit_path=dit_path,\n",
    "        )\n",
    "        cosmos_pipe = cosmos_pipe.to(\"cuda\")\n",
    "        cosmos_pipe.eval()\n",
    "        \n",
    "        print(f\"‚úÖ Pipeline loaded using alternative method\")\n",
    "        \n",
    "    except Exception as e2:\n",
    "        print(f\"‚ùå Alternative loading also failed: {e2}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import decord\n",
    "from einops import rearrange\n",
    "import time\n",
    "\n",
    "def generate_video_cosmos(input_path, prompt_embedding, num_frames=16, fps=16):\n",
    "    \"\"\"Generate video using Cosmos Predict2 with same parameters as original notebook.\"\"\"\n",
    "    \n",
    "    # Load input frame\n",
    "    if input_path.endswith(('.jpg', '.jpeg', '.png')):\n",
    "        # Input is an image\n",
    "        from PIL import Image\n",
    "        img = Image.open(input_path)\n",
    "        frames = np.array(img)[np.newaxis, ...]  # Add time dimension\n",
    "    else:\n",
    "        # Input is a video\n",
    "        vr = decord.VideoReader(input_path)\n",
    "        frames = vr[:1].asnumpy()  # Get first frame\n",
    "    \n",
    "    # Prepare input tensor\n",
    "    frames_tensor = torch.from_numpy(frames).float() / 255.0\n",
    "    frames_tensor = rearrange(frames_tensor, \"t h w c -> 1 c t h w\")\n",
    "    frames_tensor = frames_tensor.to(\"cuda\")\n",
    "    \n",
    "    print(f\"Input shape: {frames_tensor.shape}\")\n",
    "    print(f\"Generating {num_frames} frames at {fps} FPS...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        with torch.cuda.amp.autocast():\n",
    "            output = cosmos_pipe(\n",
    "                frames_tensor,\n",
    "                prompt_embedding,\n",
    "                num_frames=num_frames,\n",
    "                fps=fps,\n",
    "                seed=42\n",
    "            )\n",
    "    \n",
    "    generation_time = time.time() - start_time\n",
    "    print(f\"‚úÖ Generation complete in {generation_time:.2f} seconds\")\n",
    "    print(f\"   Speed: {num_frames/generation_time:.2f} frames/second\")\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Generation parameters matching original notebook\n",
    "# Start with lower resolution for testing, then scale up for A100\n",
    "base_params = {\n",
    "    \"num_frames\": 8,  # Start with 8 frames, can increase to 16\n",
    "    \"fps\": 16\n",
    "}\n",
    "\n",
    "# Check GPU and adjust parameters\n",
    "if torch.cuda.is_available() and 'A100' in torch.cuda.get_device_name(0):\n",
    "    print(\"üöÄ A100 detected - Using optimized settings:\")\n",
    "    generation_params = {\n",
    "        \"num_frames\": 16,  # Match original notebook\n",
    "        \"fps\": 16\n",
    "    }\n",
    "else:\n",
    "    print(\"Using conservative settings for non-A100 GPU:\")\n",
    "    generation_params = base_params\n",
    "\n",
    "print(f\"Generation parameters: num_frames={generation_params['num_frames']}, fps={generation_params['fps']}\")\n",
    "\n",
    "# Select the first prompt (matching original notebook)\n",
    "selected_prompt = prompts[0]  # \"A robotic arm picks up white paper and places it into a red square target area on the table.\"\n",
    "print(f\"\\nGenerating video for: '{selected_prompt[:50]}...'\")\n",
    "\n",
    "# Get the pre-encoded embedding\n",
    "prompt_embedding = encoded_prompts[selected_prompt]\n",
    "\n",
    "# Generate video\n",
    "output_video = generate_video_cosmos(\n",
    "    input_image_path,\n",
    "    prompt_embedding,\n",
    "    num_frames=generation_params['num_frames'],\n",
    "    fps=generation_params['fps']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import shutil\n",
    "\n",
    "def save_video(tensor, output_path=\"output_video.mp4\", fps=16, auto_backup=True):\n",
    "    \"\"\"Save tensor as video file with automatic Google Drive backup.\"\"\"\n",
    "    # Convert tensor to numpy\n",
    "    if isinstance(tensor, torch.Tensor):\n",
    "        video = tensor.cpu().numpy()\n",
    "    else:\n",
    "        video = tensor\n",
    "    \n",
    "    # Rearrange dimensions if needed\n",
    "    if video.ndim == 5:  # B C T H W\n",
    "        video = video[0]  # Remove batch\n",
    "    if video.shape[0] == 3:  # C T H W\n",
    "        video = np.transpose(video, (1, 2, 3, 0))  # T H W C\n",
    "    \n",
    "    # Normalize to 0-255\n",
    "    if video.max() <= 1.0:\n",
    "        video = (video * 255).astype(np.uint8)\n",
    "    \n",
    "    # Save video locally first\n",
    "    writer = imageio.get_writer(output_path, fps=fps)\n",
    "    for frame in video:\n",
    "        writer.append_data(frame)\n",
    "    writer.close()\n",
    "    \n",
    "    print(f\"‚úÖ Saved video locally: {output_path}\")\n",
    "    \n",
    "    # Auto-backup to Google Drive\n",
    "    if auto_backup and drive_output_dir:\n",
    "        drive_path = os.path.join(drive_output_dir, os.path.basename(output_path))\n",
    "        shutil.copy2(output_path, drive_path)\n",
    "        print(f\"‚òÅÔ∏è Backed up to Drive: {drive_path}\")\n",
    "        \n",
    "        # Also save metadata\n",
    "        metadata_path = drive_path.replace('.mp4', '_metadata.txt')\n",
    "        with open(metadata_path, 'w') as f:\n",
    "            f.write(f\"Prompt: {selected_prompt}\\n\")\n",
    "            f.write(f\"Frames: {generation_params['num_frames']}\\n\")\n",
    "            f.write(f\"FPS: {generation_params['fps']}\\n\")\n",
    "            f.write(f\"Timestamp: {datetime.now().isoformat()}\\n\")\n",
    "        print(f\"üìù Metadata saved: {metadata_path}\")\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "# Save the generated video with auto-backup\n",
    "output_filename = f\"cosmos_output_{datetime.now().strftime('%H%M%S')}.mp4\"\n",
    "output_path = save_video(output_video, output_filename, fps=16, auto_backup=True)\n",
    "\n",
    "# Display the result\n",
    "print(\"\\nGenerated video:\")\n",
    "display_video(output_path)\n",
    "\n",
    "# Optional download (in addition to Drive backup)\n",
    "download_locally = input(\"\\nDownload to your computer too? (y/n): \")\n",
    "if download_locally.lower() == 'y':\n",
    "    from google.colab import files\n",
    "    files.download(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process all prompts with auto-save to Drive\n",
    "batch_process = True  # Set to True to process all prompts\n",
    "\n",
    "if batch_process:\n",
    "    results = {}\n",
    "    \n",
    "    print(f\"üé¨ Batch processing {len(prompts)} prompts...\")\n",
    "    if drive_output_dir:\n",
    "        print(f\"üìÅ All outputs will be saved to: {drive_output_dir}\")\n",
    "    \n",
    "    for i, prompt in enumerate(prompts):\n",
    "        print(f\"\\n[{i+1}/{len(prompts)}] Processing: {prompt[:50]}...\")\n",
    "        \n",
    "        try:\n",
    "            # Generate video\n",
    "            output = generate_video_cosmos(\n",
    "                input_image_path,\n",
    "                encoded_prompts[prompt],\n",
    "                num_frames=generation_params['num_frames'],\n",
    "                fps=generation_params['fps']\n",
    "            )\n",
    "            \n",
    "            # Save with descriptive filename\n",
    "            output_file = f\"output_{i:02d}_{datetime.now().strftime('%H%M%S')}.mp4\"\n",
    "            save_video(output, output_file, fps=16, auto_backup=True)\n",
    "            results[prompt] = output_file\n",
    "            \n",
    "            # Save batch progress to Drive\n",
    "            if drive_output_dir:\n",
    "                progress_file = os.path.join(drive_output_dir, \"batch_progress.txt\")\n",
    "                with open(progress_file, 'a') as f:\n",
    "                    f.write(f\"[{i+1}/{len(prompts)}] {prompt[:80]} -> {output_file}\\n\")\n",
    "            \n",
    "            # Clear cache between generations\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ùå Failed: {e}\")\n",
    "            # Log errors to Drive\n",
    "            if drive_output_dir:\n",
    "                error_file = os.path.join(drive_output_dir, \"errors.txt\")\n",
    "                with open(error_file, 'a') as f:\n",
    "                    f.write(f\"Failed [{i+1}]: {prompt[:80]} - Error: {e}\\n\")\n",
    "            continue\n",
    "    \n",
    "    print(\"\\n‚úÖ Batch processing complete!\")\n",
    "    print(f\"Successfully generated {len(results)}/{len(prompts)} videos\")\n",
    "    \n",
    "    # Save summary to Drive\n",
    "    if drive_output_dir:\n",
    "        summary_file = os.path.join(drive_output_dir, \"summary.txt\")\n",
    "        with open(summary_file, 'w') as f:\n",
    "            f.write(f\"Batch Processing Summary\\n\")\n",
    "            f.write(f\"========================\\n\")\n",
    "            f.write(f\"Total prompts: {len(prompts)}\\n\")\n",
    "            f.write(f\"Successful: {len(results)}\\n\")\n",
    "            f.write(f\"Failed: {len(prompts) - len(results)}\\n\\n\")\n",
    "            for prompt, file in results.items():\n",
    "                f.write(f\"{prompt[:80]}...\\n  -> {file}\\n\\n\")\n",
    "        print(f\"üìä Summary saved to: {summary_file}\")\n",
    "    \n",
    "    for prompt, file in results.items():\n",
    "        print(f\"  - {prompt[:40]}... -> {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory usage and session management\n",
    "print(\"Session Status:\")\n",
    "print(f\"GPU allocated: {torch.cuda.memory_allocated()/1024**3:.2f} GB\")\n",
    "print(f\"GPU reserved: {torch.cuda.memory_reserved()/1024**3:.2f} GB\")\n",
    "print(f\"GPU free: {(torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_allocated())/1024**3:.2f} GB\")\n",
    "\n",
    "if drive_output_dir:\n",
    "    print(f\"\\n‚úÖ Outputs saved to Google Drive:\")\n",
    "    print(f\"   {drive_output_dir}\")\n",
    "    print(\"\\n‚ö†Ô∏è Your outputs are safe even if the session disconnects!\")\n",
    "    \n",
    "    # Create recovery script for next session\n",
    "    recovery_script = f\"\"\"# Recovery Script\n",
    "# Run this in a new session to continue from where you left off\n",
    "\n",
    "import os\n",
    "from google.colab import drive\n",
    "\n",
    "# Mount Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Previous output directory\n",
    "output_dir = \"{drive_output_dir}\"\n",
    "\n",
    "# List generated videos\n",
    "import glob\n",
    "videos = glob.glob(os.path.join(output_dir, \"*.mp4\"))\n",
    "print(f\"Found {{len(videos)}} generated videos:\")\n",
    "for v in videos:\n",
    "    print(f\"  - {{os.path.basename(v)}}\")\n",
    "\n",
    "# Read progress\n",
    "if os.path.exists(os.path.join(output_dir, \"batch_progress.txt\")):\n",
    "    with open(os.path.join(output_dir, \"batch_progress.txt\"), 'r') as f:\n",
    "        print(\"\\\\nBatch Progress:\")\n",
    "        print(f.read())\n",
    "\"\"\"\n",
    "    \n",
    "    recovery_path = os.path.join(drive_output_dir, \"recovery_script.py\")\n",
    "    with open(recovery_path, 'w') as f:\n",
    "        f.write(recovery_script)\n",
    "    print(f\"üìÑ Recovery script saved: {recovery_path}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No Google Drive backup - outputs will be lost if session disconnects!\")\n",
    "\n",
    "# Optional: Free memory\n",
    "cleanup = False  # Set to True to free all memory\n",
    "\n",
    "if cleanup:\n",
    "    print(\"\\nCleaning up...\")\n",
    "    \n",
    "    # Unload T5\n",
    "    if 't5_encoder' in locals():\n",
    "        t5_encoder.unload()\n",
    "    \n",
    "    # Unload Cosmos\n",
    "    if 'cosmos_pipe' in locals():\n",
    "        del cosmos_pipe\n",
    "    \n",
    "    # Clear cache\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"‚úÖ Cleanup complete\")\n",
    "    print(f\"GPU allocated: {torch.cuda.memory_allocated()/1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose T5 model based on available memory\n",
    "gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "\n",
    "if gpu_memory >= 40:  # A100\n",
    "    # Can use T5-11B for best quality\n",
    "    t5_model = \"google-t5/t5-11b\"  # 22GB in FP16\n",
    "    print(f\"Using T5-11B (best quality) on A100\")\n",
    "elif gpu_memory >= 16:  # T4 or similar\n",
    "    # Use smaller model\n",
    "    t5_model = \"google/flan-t5-xl\"  # 3GB\n",
    "    print(f\"Using Flan-T5-XL (efficient) on limited GPU\")\n",
    "else:\n",
    "    t5_model = \"google/flan-t5-base\"  # <1GB\n",
    "    print(f\"Using Flan-T5-Base (minimal) on very limited GPU\")\n",
    "\n",
    "# Initialize and load T5 encoder\n",
    "t5_encoder = OptimizedT5Encoder(model_name=t5_model)\n",
    "t5_encoder.load(use_fp16=True, use_8bit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Encode Text Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prompts for paper manipulation task\n",
    "prompts = [\n",
    "    \"The robot picks up a piece of paper from the table\",\n",
    "    \"The robot folds the paper in half\",\n",
    "    \"The robot places the folded paper back on the table\",\n",
    "    \"The robot arm reaches for a sheet of paper\",\n",
    "    \"The robot grasps the paper with its gripper\",\n",
    "]\n",
    "\n",
    "# Encode all prompts\n",
    "print(\"Encoding prompts...\")\n",
    "encoded_prompts = {}\n",
    "\n",
    "for prompt in prompts:\n",
    "    encoded = t5_encoder.encode(prompt)\n",
    "    encoded_prompts[prompt] = encoded[\"encoder_hidden_states\"]\n",
    "    print(f\"‚úÖ Encoded: '{prompt[:40]}...' Shape: {encoded['encoder_hidden_states'].shape}\")\n",
    "\n",
    "print(f\"\\nüíæ Current GPU memory: {torch.cuda.memory_allocated()/1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Load Cosmos Predict2 Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cosmos_predict2.inference import (\n",
    "    Video2WorldPipeline,\n",
    "    get_cosmos_predict2_video2world_pipeline,\n",
    ")\n",
    "\n",
    "print(f\"Loading Cosmos Predict2-{MODEL_SIZE} pipeline...\")\n",
    "\n",
    "# Create pipeline configuration\n",
    "config = get_cosmos_predict2_video2world_pipeline(model_size=MODEL_SIZE)\n",
    "\n",
    "# Update config to use our downloaded checkpoint\n",
    "config['dit_checkpoint_path'] = os.path.join(\n",
    "    checkpoint_dir,\n",
    "    \"model-720p-16fps.pt\"  # or \"model-720p-10fps.pt\" for 10fps\n",
    ")\n",
    "\n",
    "# Initialize pipeline\n",
    "cosmos_pipe = Video2WorldPipeline.from_config(config)\n",
    "cosmos_pipe = cosmos_pipe.to(\"cuda\")\n",
    "cosmos_pipe.eval()\n",
    "\n",
    "print(f\"‚úÖ Cosmos pipeline loaded\")\n",
    "print(f\"üíæ Current GPU memory: {torch.cuda.memory_allocated()/1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Create or Load Input Video\\n\n",
    "You can either upload a video or create a simple test video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from IPython.display import HTML, display\n",
    "import base64\n",
    "\n",
    "def create_test_video(output_path=\"test_input.mp4\", width=1280, height=720, fps=16, duration=1):\n",
    "    \"\"\"Create a simple test video with a moving object.\"\"\"\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    num_frames = int(fps * duration)\n",
    "    \n",
    "    for i in range(num_frames):\n",
    "        # Create a frame with gradient background\n",
    "        frame = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "        \n",
    "        # Add gradient background\n",
    "        for y in range(height):\n",
    "            frame[y, :] = [int(255 * y / height), 100, 150]\n",
    "        \n",
    "        # Add moving circle (simulating object)\n",
    "        x = int(width * (0.2 + 0.6 * i / num_frames))\n",
    "        y = height // 2\n",
    "        cv2.circle(frame, (x, y), 50, (255, 255, 255), -1)\n",
    "        \n",
    "        # Add text\n",
    "        cv2.putText(frame, \"Test Input\", (50, 50), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "        \n",
    "        out.write(frame)\n",
    "    \n",
    "    out.release()\n",
    "    print(f\"Created test video: {output_path}\")\n",
    "    return output_path\n",
    "\n",
    "def display_video(video_path):\n",
    "    \"\"\"Display video in notebook.\"\"\"\n",
    "    video = open(video_path, 'rb').read()\n",
    "    encoded = base64.b64encode(video).decode('ascii')\n",
    "    display(HTML(f'''\n",
    "    <video width=\"640\" height=\"360\" controls>\n",
    "        <source src=\"data:video/mp4;base64,{encoded}\" type=\"video/mp4\">\n",
    "    </video>\n",
    "    '''))\n",
    "\n",
    "# Create or upload video\n",
    "use_test_video = True  # Set to False if you want to upload your own\n",
    "\n",
    "if use_test_video:\n",
    "    input_video_path = create_test_video()\n",
    "    display_video(input_video_path)\n",
    "else:\n",
    "    from google.colab import files\n",
    "    print(\"Please upload a video file:\")\n",
    "    uploaded = files.upload()\n",
    "    input_video_path = list(uploaded.keys())[0]\n",
    "    print(f\"Uploaded: {input_video_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Generate Video with Cosmos Predict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import decord\n",
    "from einops import rearrange\n",
    "import time\n",
    "\n",
    "def generate_video_cosmos(input_path, prompt_embedding, num_frames=121, fps=16):\n",
    "    \"\"\"Generate video using Cosmos Predict2.\"\"\"\n",
    "    \n",
    "    # Load input video\n",
    "    vr = decord.VideoReader(input_path)\n",
    "    frames = vr[:1].asnumpy()  # Get first frame\n",
    "    \n",
    "    # Prepare input tensor\n",
    "    frames_tensor = torch.from_numpy(frames).float() / 255.0\n",
    "    frames_tensor = rearrange(frames_tensor, \"t h w c -> 1 c t h w\")\n",
    "    frames_tensor = frames_tensor.to(\"cuda\")\n",
    "    \n",
    "    print(f\"Input shape: {frames_tensor.shape}\")\n",
    "    print(f\"Generating {num_frames} frames at {fps} FPS...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        with torch.cuda.amp.autocast():\n",
    "            output = cosmos_pipe(\n",
    "                frames_tensor,\n",
    "                prompt_embedding,\n",
    "                num_frames=num_frames,\n",
    "                fps=fps,\n",
    "                seed=42\n",
    "            )\n",
    "    \n",
    "    generation_time = time.time() - start_time\n",
    "    print(f\"‚úÖ Generation complete in {generation_time:.2f} seconds\")\n",
    "    print(f\"   Speed: {num_frames/generation_time:.2f} frames/second\")\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Select a prompt and generate\n",
    "selected_prompt = prompts[0]  # \"The robot picks up a piece of paper from the table\"\n",
    "print(f\"\\nGenerating video for: '{selected_prompt}'\")\n",
    "\n",
    "# Get the pre-encoded embedding\n",
    "prompt_embedding = encoded_prompts[selected_prompt]\n",
    "\n",
    "# Generate video\n",
    "output_video = generate_video_cosmos(\n",
    "    input_video_path,\n",
    "    prompt_embedding,\n",
    "    num_frames=121,  # ~7.5 seconds at 16fps\n",
    "    fps=16\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save and Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "\n",
    "def save_video(tensor, output_path=\"output_video.mp4\", fps=16):\n",
    "    \"\"\"Save tensor as video file.\"\"\"\n",
    "    # Convert tensor to numpy\n",
    "    if isinstance(tensor, torch.Tensor):\n",
    "        video = tensor.cpu().numpy()\n",
    "    else:\n",
    "        video = tensor\n",
    "    \n",
    "    # Rearrange dimensions if needed\n",
    "    if video.ndim == 5:  # B C T H W\n",
    "        video = video[0]  # Remove batch\n",
    "    if video.shape[0] == 3:  # C T H W\n",
    "        video = np.transpose(video, (1, 2, 3, 0))  # T H W C\n",
    "    \n",
    "    # Normalize to 0-255\n",
    "    if video.max() <= 1.0:\n",
    "        video = (video * 255).astype(np.uint8)\n",
    "    \n",
    "    # Save video\n",
    "    writer = imageio.get_writer(output_path, fps=fps)\n",
    "    for frame in video:\n",
    "        writer.append_data(frame)\n",
    "    writer.close()\n",
    "    \n",
    "    print(f\"Saved video to: {output_path}\")\n",
    "    return output_path\n",
    "\n",
    "# Save the generated video\n",
    "output_path = save_video(output_video, \"cosmos_output.mp4\", fps=16)\n",
    "\n",
    "# Display the result\n",
    "print(\"\\nGenerated video:\")\n",
    "display_video(output_path)\n",
    "\n",
    "# Download option\n",
    "from google.colab import files\n",
    "download = input(\"Download the video? (y/n): \")\n",
    "if download.lower() == 'y':\n",
    "    files.download(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Batch Processing (Optional)\\n\n",
    "Process multiple prompts efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all prompts\n",
    "batch_process = False  # Set to True to process all prompts\n",
    "\n",
    "if batch_process:\n",
    "    results = {}\n",
    "    \n",
    "    for i, prompt in enumerate(prompts):\n",
    "        print(f\"\\n[{i+1}/{len(prompts)}] Processing: {prompt[:50]}...\")\n",
    "        \n",
    "        # Generate video\n",
    "        output = generate_video_cosmos(\n",
    "            input_video_path,\n",
    "            encoded_prompts[prompt],\n",
    "            num_frames=61,  # Shorter for batch processing\n",
    "            fps=16\n",
    "        )\n",
    "        \n",
    "        # Save\n",
    "        output_file = f\"output_{i:02d}.mp4\"\n",
    "        save_video(output, output_file)\n",
    "        results[prompt] = output_file\n",
    "        \n",
    "        # Clear cache between generations\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    print(\"\\n‚úÖ Batch processing complete!\")\n",
    "    for prompt, file in results.items():\n",
    "        print(f\"  - {prompt[:40]}... -> {file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Memory Management and Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory usage summary\n",
    "print(\"Memory Usage Summary:\")\n",
    "print(f\"GPU allocated: {torch.cuda.memory_allocated()/1024**3:.2f} GB\")\n",
    "print(f\"GPU reserved: {torch.cuda.memory_reserved()/1024**3:.2f} GB\")\n",
    "print(f\"GPU free: {(torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_allocated())/1024**3:.2f} GB\")\n",
    "\n",
    "# Optional: Free memory\n",
    "cleanup = False  # Set to True to free all memory\n",
    "\n",
    "if cleanup:\n",
    "    print(\"\\nCleaning up...\")\n",
    "    \n",
    "    # Unload T5\n",
    "    if 't5_encoder' in locals():\n",
    "        t5_encoder.unload()\n",
    "    \n",
    "    # Unload Cosmos\n",
    "    if 'cosmos_pipe' in locals():\n",
    "        del cosmos_pipe\n",
    "    \n",
    "    # Clear cache\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"‚úÖ Cleanup complete\")\n",
    "    print(f\"GPU allocated: {torch.cuda.memory_allocated()/1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips and Troubleshooting\\n\n",
    "\\n\n",
    "### Memory Optimization:\\n\n",
    "- **A100 (40GB)**: Can run T5-11B + Cosmos-14B\\n\n",
    "- **T4 (16GB)**: Use Flan-T5-XL + Cosmos-2B\\n\n",
    "- **Low memory**: Use 8-bit quantization or unload T5 after encoding\\n\n",
    "\\n\n",
    "### Performance Tips:\\n\n",
    "- Enable TF32 on A100 for 2-3x speedup\\n\n",
    "- Use FP16 (half precision) for memory efficiency\\n\n",
    "- Batch encode prompts before generation\\n\n",
    "\\n\n",
    "### Common Issues:\\n\n",
    "1. **OOM Error**: Reduce batch size or use smaller models\\n\n",
    "2. **Slow generation**: Check GPU type, use smaller num_frames\\n\n",
    "3. **Import errors**: Restart runtime after installing packages"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}