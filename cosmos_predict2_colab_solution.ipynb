{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosmos Predict2 on Google Colab - Complete Solution\n",
    "\n",
    "This notebook provides a complete solution for running Cosmos-Predict2 on Google Colab, which now uses Python 3.12 (or 3.11 in fallback).\n",
    "\n",
    "**Problem**: \n",
    "- Cosmos-Predict2 requires Python 3.10 (flash-attn only has cp310 wheels)\n",
    "- Colab default runtime: Python 3.12\n",
    "- Colab fallback runtime: Python 3.11\n",
    "- Neither works with Cosmos-Predict2!\n",
    "\n",
    "**Solution**: We'll install Python 3.10 using deadsnakes PPA and use it with pip.\n",
    "\n",
    "**Requirements**:\n",
    "- Google Colab with GPU (A100, V100, or T4)\n",
    "- About 5-10 minutes for setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Check Current Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"üîç Current Environment Check:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check current Python version\n",
    "current_version = sys.version_info\n",
    "print(f\"Current Python: {current_version.major}.{current_version.minor}.{current_version.micro}\")\n",
    "print(f\"Python path: {sys.executable}\")\n",
    "\n",
    "# Check GPU\n",
    "try:\n",
    "    import torch\n",
    "    if torch.cuda.is_available():\n",
    "        gpu_name = torch.cuda.get_device_name(0)\n",
    "        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "        print(f\"\\nGPU: {gpu_name} ({gpu_memory:.1f} GB)\")\n",
    "        print(f\"CUDA: {torch.version.cuda}\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è No GPU detected\")\n",
    "        gpu_memory = 0\n",
    "except:\n",
    "    print(\"\\nTorch not yet installed\")\n",
    "    gpu_memory = 0\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "if current_version.minor != 10:\n",
    "    print(f\"\\n‚ö†Ô∏è Python {current_version.major}.{current_version.minor} detected.\")\n",
    "    print(\"We need Python 3.10 for Cosmos-Predict2.\")\n",
    "    print(\"\\nüìù Next step: Install Python 3.10 alongside the system Python.\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ Python 3.10 already available!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Install Python 3.10\n",
    "\n",
    "We'll install Python 3.10 using the deadsnakes PPA, which provides Python versions for Ubuntu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Install Python 3.10 from deadsnakes PPA\n",
    "echo \"üì¶ Installing Python 3.10...\"\n",
    "echo \"This will take about 1-2 minutes...\"\n",
    "echo \"\"\n",
    "\n",
    "# Add deadsnakes PPA\n",
    "apt-get update -qq\n",
    "apt-get install -qq software-properties-common\n",
    "add-apt-repository -y ppa:deadsnakes/ppa\n",
    "\n",
    "# Install Python 3.10 and required packages\n",
    "apt-get update -qq\n",
    "apt-get install -qq python3.10 python3.10-venv python3.10-dev python3.10-distutils\n",
    "\n",
    "# Install pip for Python 3.10\n",
    "curl -sS https://bootstrap.pypa.io/get-pip.py | python3.10\n",
    "\n",
    "echo \"\"\n",
    "echo \"‚úÖ Python 3.10 installation complete!\"\n",
    "\n",
    "# Verify installation\n",
    "echo \"\"\n",
    "echo \"Verification:\"\n",
    "python3.10 --version\n",
    "python3.10 -m pip --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create Python 3.10 Virtual Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Create a virtual environment with Python 3.10\n",
    "echo \"üîß Creating Python 3.10 virtual environment...\"\n",
    "\n",
    "# Create venv\n",
    "python3.10 -m venv /content/cosmos_env\n",
    "\n",
    "# Activate and verify\n",
    "source /content/cosmos_env/bin/activate\n",
    "which python\n",
    "python --version\n",
    "\n",
    "echo \"‚úÖ Virtual environment created with Python 3.10\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Install Cosmos-Predict2 in Python 3.10 Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Install packages using Python 3.10\n",
    "echo \"üì¶ Installing Cosmos-Predict2 and dependencies...\"\n",
    "echo \"This will take 3-5 minutes...\"\n",
    "echo \"\"\n",
    "\n",
    "# Use the virtual environment's pip\n",
    "source /content/cosmos_env/bin/activate\n",
    "\n",
    "# Upgrade pip\n",
    "python -m pip install --upgrade pip setuptools wheel\n",
    "\n",
    "# Install PyTorch with CUDA support\n",
    "python -m pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "# Install Cosmos-Predict2\n",
    "python -m pip install \"cosmos-predict2[cu126]\" --extra-index-url https://nvidia-cosmos.github.io/cosmos-dependencies/cu126_torch260/simple\n",
    "\n",
    "# Install additional dependencies\n",
    "python -m pip install transformers accelerate bitsandbytes\n",
    "python -m pip install decord einops \"imageio[ffmpeg]\" opencv-python-headless pillow\n",
    "\n",
    "echo \"\"\n",
    "echo \"‚úÖ Installation complete!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Configure Jupyter to Use Python 3.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the notebook to use Python 3.10 from our virtual environment\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the virtual environment to sys.path\n",
    "venv_path = '/content/cosmos_env'\n",
    "python_path = f'{venv_path}/bin/python3.10'\n",
    "site_packages = f'{venv_path}/lib/python3.10/site-packages'\n",
    "\n",
    "# Update sys.path\n",
    "if site_packages not in sys.path:\n",
    "    sys.path.insert(0, site_packages)\n",
    "\n",
    "# Set environment variables\n",
    "os.environ['VIRTUAL_ENV'] = venv_path\n",
    "os.environ['PATH'] = f\"{venv_path}/bin:{os.environ['PATH']}\"\n",
    "\n",
    "print(\"üîß Configuring notebook to use Python 3.10 environment...\")\n",
    "print(f\"Virtual env: {venv_path}\")\n",
    "print(f\"Site packages: {site_packages}\")\n",
    "\n",
    "# Now we need to restart the kernel with the new Python\n",
    "# But first, let's verify we can import from the venv\n",
    "try:\n",
    "    # This should work after adding to sys.path\n",
    "    import torch\n",
    "    print(f\"\\n‚úÖ PyTorch version: {torch.__version__}\")\n",
    "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "except ImportError as e:\n",
    "    print(f\"\\n‚ö†Ô∏è Import error: {e}\")\n",
    "    print(\"You may need to restart the kernel.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Test Cosmos-Predict2 Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use subprocess to run Python 3.10 directly\n",
    "import subprocess\n",
    "import json\n",
    "\n",
    "# Test script\n",
    "test_script = \"\"\"\n",
    "import sys\n",
    "import json\n",
    "\n",
    "result = {}\n",
    "result['python_version'] = f\"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}\"\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    result['torch_version'] = torch.__version__\n",
    "    result['cuda_available'] = torch.cuda.is_available()\n",
    "    if torch.cuda.is_available():\n",
    "        result['gpu_name'] = torch.cuda.get_device_name(0)\n",
    "except Exception as e:\n",
    "    result['torch_error'] = str(e)\n",
    "\n",
    "try:\n",
    "    from cosmos_predict2.inference import Video2WorldPipeline\n",
    "    result['cosmos_import'] = 'success'\n",
    "except Exception as e:\n",
    "    result['cosmos_import'] = f'failed: {e}'\n",
    "\n",
    "print(json.dumps(result))\n",
    "\"\"\"\n",
    "\n",
    "# Run test in Python 3.10\n",
    "result = subprocess.run(\n",
    "    ['/content/cosmos_env/bin/python', '-c', test_script],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "if result.returncode == 0:\n",
    "    test_results = json.loads(result.stdout)\n",
    "    \n",
    "    print(\"üîç Python 3.10 Environment Test:\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Python version: {test_results.get('python_version')}\")\n",
    "    print(f\"PyTorch version: {test_results.get('torch_version', 'Not installed')}\")\n",
    "    print(f\"CUDA available: {test_results.get('cuda_available', False)}\")\n",
    "    if 'gpu_name' in test_results:\n",
    "        print(f\"GPU: {test_results['gpu_name']}\")\n",
    "    \n",
    "    cosmos_status = test_results.get('cosmos_import', 'unknown')\n",
    "    if cosmos_status == 'success':\n",
    "        print(\"\\n‚úÖ Cosmos-Predict2 imported successfully!\")\n",
    "    else:\n",
    "        print(f\"\\n‚ùå Cosmos import: {cosmos_status}\")\n",
    "else:\n",
    "    print(\"‚ùå Test failed:\")\n",
    "    print(result.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Create Helper Function to Run Python 3.10 Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "def run_python310(code, return_output=False):\n",
    "    \"\"\"\n",
    "    Run code using Python 3.10 from the virtual environment.\n",
    "    \n",
    "    Args:\n",
    "        code: Python code to execute\n",
    "        return_output: If True, return the output as string\n",
    "    \n",
    "    Returns:\n",
    "        Output string if return_output=True, else None\n",
    "    \"\"\"\n",
    "    with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:\n",
    "        f.write(code)\n",
    "        temp_file = f.name\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            ['/content/cosmos_env/bin/python', temp_file],\n",
    "            capture_output=True,\n",
    "            text=True\n",
    "        )\n",
    "        \n",
    "        if result.returncode != 0:\n",
    "            print(\"‚ùå Error:\")\n",
    "            print(result.stderr)\n",
    "            return None\n",
    "        \n",
    "        if return_output:\n",
    "            return result.stdout\n",
    "        else:\n",
    "            print(result.stdout)\n",
    "    finally:\n",
    "        os.unlink(temp_file)\n",
    "\n",
    "# Test the helper function\n",
    "test_code = \"\"\"\n",
    "import sys\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(\"Hello from Python 3.10!\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"Testing helper function...\\n\")\n",
    "run_python310(test_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Complete Example - Generate a Video with Cosmos-Predict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete script to generate a video using Python 3.10\n",
    "cosmos_script = \"\"\"\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "print(\"üöÄ Starting Cosmos-Predict2 video generation...\\n\")\n",
    "\n",
    "# Import libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from transformers import T5EncoderModel, T5Tokenizer\n",
    "from cosmos_predict2.inference import (\n",
    "    Video2WorldPipeline,\n",
    "    get_cosmos_predict2_video2world_pipeline,\n",
    ")\n",
    "from einops import rearrange\n",
    "import imageio\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "# Check GPU\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    print(f\"GPU: {gpu_name} ({gpu_memory:.1f} GB)\")\n",
    "else:\n",
    "    print(\"No GPU detected\")\n",
    "    gpu_memory = 16\n",
    "\n",
    "# Auto-select model size\n",
    "if gpu_memory >= 40:\n",
    "    MODEL_SIZE = \"14B\"\n",
    "elif gpu_memory >= 24:\n",
    "    MODEL_SIZE = \"5B\"\n",
    "else:\n",
    "    MODEL_SIZE = \"2B\"\n",
    "\n",
    "print(f\"Using Cosmos-{MODEL_SIZE} model\\n\")\n",
    "\n",
    "# Download checkpoint\n",
    "print(\"Downloading checkpoint...\")\n",
    "checkpoint_dir = snapshot_download(\n",
    "    repo_id=f\"nvidia/Cosmos-Predict2-{MODEL_SIZE}-Video2World\",\n",
    "    cache_dir=\"/content/cosmos_checkpoints\",\n",
    "    resume_download=True\n",
    ")\n",
    "print(\"Checkpoint downloaded\\n\")\n",
    "\n",
    "# Load T5 encoder\n",
    "print(\"Loading T5 encoder...\")\n",
    "t5_model = \"google/flan-t5-base\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(t5_model)\n",
    "text_encoder = T5EncoderModel.from_pretrained(t5_model).half().to(\"cuda\")\n",
    "text_encoder.eval()\n",
    "print(\"T5 loaded\\n\")\n",
    "\n",
    "# Load Cosmos pipeline\n",
    "print(\"Loading Cosmos pipeline...\")\n",
    "config = get_cosmos_predict2_video2world_pipeline(model_size=MODEL_SIZE)\n",
    "cosmos_pipe = Video2WorldPipeline.from_config(config)\n",
    "cosmos_pipe = cosmos_pipe.to(\"cuda\")\n",
    "cosmos_pipe.eval()\n",
    "print(\"Cosmos pipeline loaded\\n\")\n",
    "\n",
    "# Create test input\n",
    "print(\"Creating test input...\")\n",
    "img = np.ones((720, 1280, 3), dtype=np.uint8) * 100\n",
    "img[200:520, 400:880] = [200, 150, 100]\n",
    "Image.fromarray(img).save(\"/content/test_input.jpg\")\n",
    "\n",
    "# Encode prompt\n",
    "prompt = \"A robotic arm moves across the table\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=77,\n",
    "                  padding=\"max_length\", truncation=True).to(\"cuda\")\n",
    "with torch.no_grad():\n",
    "    text_embeddings = text_encoder(**inputs).last_hidden_state\n",
    "\n",
    "# Prepare input\n",
    "frames = np.array(Image.open(\"/content/test_input.jpg\"))[np.newaxis, ...]\n",
    "frames_tensor = torch.from_numpy(frames).float() / 255.0\n",
    "frames_tensor = rearrange(frames_tensor, \"t h w c -> 1 c t h w\").to(\"cuda\")\n",
    "\n",
    "# Generate video\n",
    "print(\"Generating video...\")\n",
    "with torch.no_grad():\n",
    "    with torch.cuda.amp.autocast():\n",
    "        output = cosmos_pipe(\n",
    "            frames_tensor,\n",
    "            text_embeddings,\n",
    "            num_frames=8,  # Quick test\n",
    "            fps=8,\n",
    "            seed=42\n",
    "        )\n",
    "\n",
    "# Save video\n",
    "if isinstance(output, torch.Tensor):\n",
    "    video = output.cpu().numpy()\n",
    "else:\n",
    "    video = output\n",
    "\n",
    "if video.ndim == 5:\n",
    "    video = video[0]\n",
    "if video.shape[0] == 3:\n",
    "    video = np.transpose(video, (1, 2, 3, 0))\n",
    "if video.max() <= 1.0:\n",
    "    video = (video * 255).astype(np.uint8)\n",
    "\n",
    "# Save\n",
    "writer = imageio.get_writer(\"/content/output.mp4\", fps=8)\n",
    "for frame in video:\n",
    "    writer.append_data(frame)\n",
    "writer.close()\n",
    "\n",
    "print(\"\\n‚úÖ Video saved to /content/output.mp4\")\n",
    "print(f\"Generated {len(video)} frames\")\n",
    "\"\"\"\n",
    "\n",
    "# Run the script\n",
    "print(\"Running Cosmos-Predict2 generation script...\")\n",
    "print(\"This will take 2-3 minutes for first run (downloading models)\\n\")\n",
    "print(\"=\"*60)\n",
    "run_python310(cosmos_script)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Display the Generated Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the generated video\n",
    "import os\n",
    "from IPython.display import HTML\n",
    "import base64\n",
    "\n",
    "if os.path.exists(\"/content/output.mp4\"):\n",
    "    with open(\"/content/output.mp4\", \"rb\") as f:\n",
    "        video_data = f.read()\n",
    "    \n",
    "    encoded = base64.b64encode(video_data).decode('ascii')\n",
    "    \n",
    "    display(HTML(f'''\n",
    "    <video width=\"640\" controls autoplay loop>\n",
    "        <source src=\"data:video/mp4;base64,{encoded}\" type=\"video/mp4\">\n",
    "    </video>\n",
    "    '''))\n",
    "    \n",
    "    print(\"\\nüéâ Success! Cosmos-Predict2 is working!\")\n",
    "    print(\"\\nYou can now:\")\n",
    "    print(\"1. Modify the prompt for different outputs\")\n",
    "    print(\"2. Increase num_frames for longer videos\")\n",
    "    print(\"3. Use your own input images\")\n",
    "else:\n",
    "    print(\"‚ùå Video not found. Check the output from the previous cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Complete!\n",
    "\n",
    "You now have Cosmos-Predict2 running on Google Colab with Python 3.10!\n",
    "\n",
    "### How This Works:\n",
    "1. We installed Python 3.10 alongside Colab's Python\n",
    "2. Created a virtual environment with Python 3.10\n",
    "3. Installed all packages in that environment\n",
    "4. Use `run_python310()` helper to execute code\n",
    "\n",
    "### Tips:\n",
    "- All Cosmos code must run through `run_python310()`\n",
    "- Save outputs to `/content/` to access from notebook\n",
    "- Mount Google Drive to prevent data loss\n",
    "\n",
    "### Troubleshooting:\n",
    "- If imports fail, check the virtual environment installation\n",
    "- For OOM errors, reduce `num_frames` or model size\n",
    "- The first run downloads models (2-5 minutes)\n",
    "\n",
    "### Alternative Approach:\n",
    "If this doesn't work, consider:\n",
    "1. Using a local environment with Python 3.10\n",
    "2. Using a cloud service that supports custom environments\n",
    "3. Building custom wheels for Python 3.11/3.12 (advanced)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}